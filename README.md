# ğŸš€ Modular ETL Pipeline Using PySpark, Delta Lake & REST APIs

This repository documents an end-to-end ETL (Extract, Transform, Load) pipeline for integrating and processing data from **Zoho**, **HubSpot**, and **Custify** using **PySpark**, **Delta Lake**, and **REST APIs**.

---

## ğŸ“Œ Project Overview

The pipeline follows a clean, modular structure with three distinct phases:

- **Extraction**: API data from Zoho (Credit Notes), HubSpot (Deals), Custify (Company metrics)  
- **Transformation**: Data cleaning and normalization with PySpark  
- **Loading**: Writes into Databricks Delta tables for analysis

---

## ğŸ“ Project Structure
ğŸ”¹ extract/ â€“ Data Ingestion Scripts
- extract_zoho.py â€“ Extracts Credit Notes from Zoho API
- extract_hubspot.py â€“ Extracts Deal Data from HubSpot
- extract_custify.py â€“ Extracts Company Metrics from Custify

ğŸ”¹ transform/ â€“ Data Cleaning & Transformation
- transform_zoho.py â€“ Normalizes Zoho data
- transform_hubspot.py â€“ Cleans HubSpot pipeline data
- transform_custify.py â€“ Transforms Custify API response

ğŸ”¹ load/ â€“ Data Loading into Delta Tables
- load_zoho.py â€“ Loads Zoho data to Databricks
- load_hubspot.py â€“ Loads HubSpot deals to target tables
- load_custify.py â€“ Pushes Custify data to Delta Lake

ğŸ”¹ utils/ â€“ Reusable Utilities
- spark_utils.py â€“ Spark session & Delta helpers
- api_helpers.py â€“ API authentication, pagination
- logging.py â€“ Custom logging setup

ğŸ”¹ config/ â€“ Configuration & Secrets
- config.yaml â€“ API tokens, table names, endpoints

ğŸ”¹ Root Files
- main.py â€“ Main pipeline runner

- requirements.txt â€“ Python package dependencies

---

## âš™ï¸ Technologies Used

- ğŸ Python  
- ğŸ”¥ PySpark  
- ğŸ’¾ Delta Lake  
- ğŸŒ REST APIs (Zoho, HubSpot, Custify)  
- âš™ï¸ YAML for configuration  
- ğŸ§± Modular architecture  

---

## ğŸ”Œ Data Sources

| Source   | Method    | Purpose                     |
|----------|-----------|-----------------------------|
| Zoho     | REST API  | Finance Credit Notes        |
| HubSpot  | REST API  | Deals Pipeline              |
| Custify  | REST API  | Customer Health & Metrics   |

---

## â–¶ï¸ How to Run

### 1ï¸âƒ£ Install Dependencies
pip install -r requirements.txt


---

## âš™ï¸ Technologies Used

- ğŸ Python  
- ğŸ”¥ PySpark  
- ğŸ’¾ Delta Lake  
- ğŸŒ REST APIs (Zoho, HubSpot, Custify)  
- âš™ï¸ YAML for configuration  
- ğŸ§± Modular architecture  

---

## ğŸ”Œ Data Sources

| Source   | Method    | Purpose                     |
|----------|-----------|-----------------------------|
| Zoho     | REST API  | Finance Credit Notes        |
| HubSpot  | REST API  | Deals Pipeline              |
| Custify  | REST API  | Customer Health & Metrics   |

---

## â–¶ï¸ How to Run

### 1ï¸âƒ£ Install Dependencies

bash
pip install -r requirements.txt

---

### 2ï¸âƒ£ Configure config/config.yaml

zoho:
 - base_url: "https://www.zohoapis.com/billing/v1/creditnotes"
 - table: "zoho_creditnotes"

hubspot:
- access_token: "your-hubspot-token"
- table: "hubspot_deals"

custify:
- api_token: "your-custify-token"
- "custify_companies"

---

ğŸ” Secrets Management

- ğŸ”’ Never hardcode API tokens or secrets
- âœ… Use Databricks Secrets in production
- â• Extend to more APIs (e.g., Jira, Salesforce)

## ğŸ‘¤ Authors & Maintainers

**[Avinash M]** â€“ Business Analyst  
ğŸ“§ Email: [avinashsolai@gmail.com]  
ğŸ”— LinkedIn: [www.linkedin.com/in/avinash-m-va73] 

